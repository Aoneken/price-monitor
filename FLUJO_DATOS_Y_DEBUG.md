# üìä Flujo de Datos y Archivos Debug - Explicaci√≥n Completa

## üéØ Resumen Ejecutivo

**Lo m√°s importante:** Los archivos debug (HTML/PNG) **NO** se usan para generar la base de datos. Son **completamente independientes** y solo sirven para troubleshooting.

---

## üîÑ Flujo Real del Sistema

### 1Ô∏è‚É£ **Scraping en Tiempo Real** (Lo que S√ç ocurre)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Usuario   ‚îÇ
‚îÇ inicia      ‚îÇ
‚îÇ scraping    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Streamlit app.py                           ‚îÇ
‚îÇ  - Configura fechas                         ‚îÇ
‚îÇ  - Selecciona plataformas                   ‚îÇ
‚îÇ  - Llama a scrapers                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Scraper (Airbnb/Booking)                   ‚îÇ
‚îÇ  1. Abre navegador Playwright               ‚îÇ
‚îÇ  2. Navega a la URL de la propiedad         ‚îÇ
‚îÇ  3. Extrae precio del HTML EN MEMORIA       ‚îÇ ‚Üê CLAVE: En memoria, no de archivo
‚îÇ  4. Cierra navegador                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  DataManager                                ‚îÇ
‚îÇ  - Recibe datos de precio                  ‚îÇ
‚îÇ  - Los agrega a CSV                         ‚îÇ
‚îÇ  - data/price_history.csv                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Datos guardados directamente:**
```csv
platform,checkin,checkout,price_usd,guests,scraped_at,url,property_name
Airbnb,2025-11-06,2025-11-08,150.00,2,2025-11-06T14:30:00,...,Aizeder Eco Container
Booking,2025-11-06,2025-11-08,155.00,2,2025-11-06T14:32:00,...,Aizeder Eco Container
```

---

## üêõ Archivos Debug (Opcionales y Separados)

### ¬øCu√°ndo se generan?

**Solo se crean archivos debug cuando:**

1. **`debug_first=True`** en `scrape_date_range()` (actualmente FALSE en app.py)
2. **O cuando NO se encuentra precio** (para debugging autom√°tico)

### ¬øQu√© contienen?

```
debug/
‚îú‚îÄ‚îÄ airbnb_Aizeder_Eco_Container_20251106_143052.html  ‚Üê HTML capturado
‚îú‚îÄ‚îÄ airbnb_Aizeder_Eco_Container_20251106_143052.png   ‚Üê Screenshot
‚îú‚îÄ‚îÄ booking_Casa_del_Bosque_20251107_150330.html
‚îî‚îÄ‚îÄ booking_Casa_del_Bosque_20251107_150330.png
```

**Prop√≥sito:**
- Ver exactamente qu√© HTML recibi√≥ el scraper
- Debuggear selectores CSS cuando fallan
- Verificar si la p√°gina carg√≥ correctamente
- **NO se usan para extraer datos posteriormente**

---

## ‚ùå Lo que NO Ocurre (Malentendidos Comunes)

### ‚ùå Mito 1: "Los datos se extraen de los HTML guardados"

**Falso.** Los datos se extraen **en tiempo real** del HTML en memoria mientras el navegador est√° abierto. Los archivos HTML son solo copias de respaldo.

### ‚ùå Mito 2: "Si se reemplaza el HTML debug, se pierden datos"

**Falso.** Los datos ya est√°n guardados en `price_history.csv`. Reemplazar o borrar archivos debug **no afecta la base de datos**.

### ‚ùå Mito 3: "Necesito los archivos debug para que funcione el sistema"

**Falso.** El sistema funciona perfectamente sin archivos debug. De hecho, est√°n **desactivados por defecto** en la app (`debug_first=False`).

---

## ‚úÖ Soluci√≥n al Problema de Nombres Duplicados

### Problema Original

**Antes de la correcci√≥n:**
```python
# Ambas propiedades generaban el mismo nombre de archivo
screenshot_path = f'debug_airbnb_20251106.png'
html_path = f'debug_airbnb_20251106.html'
```

**Resultado:**
```
Scraping Propiedad A (06/11) ‚Üí debug_airbnb_20251106.html
Scraping Propiedad B (06/11) ‚Üí debug_airbnb_20251106.html  ‚Üê SOBRESCRIBE!
```

### Soluci√≥n Implementada

**Ahora con nombres √∫nicos:**
```python
# Nombre de archivo √∫nico: plataforma + propiedad + fecha + timestamp
timestamp = datetime.now().strftime("%H%M%S")
safe_property_name = re.sub(r'[^\w\s-]', '', property_name).strip().replace(' ', '_')[:30]

filename = f'{platform}_{safe_property_name}_{checkin_date.strftime("%Y%m%d")}_{timestamp}.html'
```

**Resultado:**
```
Scraping Aizeder (06/11 14:30) ‚Üí airbnb_Aizeder_Eco_Container_20251106_143052.html
Scraping Casa Bosque (06/11 14:30) ‚Üí airbnb_Casa_Bosque_20251106_143055.html
Scraping Aizeder (07/11 10:00) ‚Üí airbnb_Aizeder_Eco_Container_20251107_100012.html
```

**Ventajas:**
- ‚úÖ Nunca se pisan archivos
- ‚úÖ F√°cil identificar qu√© propiedad
- ‚úÖ Ordenados cronol√≥gicamente
- ‚úÖ Timestamp √∫nico previene colisiones

---

## üìÅ Organizaci√≥n de Archivos

### Estructura Completa

```
price-monitor/
‚îÇ
‚îú‚îÄ‚îÄ data/                              ‚Üê BASE DE DATOS PRINCIPAL
‚îÇ   ‚îú‚îÄ‚îÄ price_history.csv              ‚Üê ‚òÖ Todos los datos hist√≥ricos
‚îÇ   ‚îî‚îÄ‚îÄ scrape_runs.json               ‚Üê Log anti-duplicado 48h
‚îÇ
‚îú‚îÄ‚îÄ debug/                             ‚Üê ARCHIVOS DE TROUBLESHOOTING (opcionales)
‚îÇ   ‚îú‚îÄ‚îÄ airbnb_Aizeder_Eco_Container_20251106_143052.html
‚îÇ   ‚îú‚îÄ‚îÄ airbnb_Aizeder_Eco_Container_20251106_143052.png
‚îÇ   ‚îú‚îÄ‚îÄ airbnb_Casa_del_Bosque_20251107_100012.html
‚îÇ   ‚îú‚îÄ‚îÄ airbnb_Casa_del_Bosque_20251107_100012.png
‚îÇ   ‚îú‚îÄ‚îÄ booking_Aizeder_Eco_Container_20251106_143230.html
‚îÇ   ‚îî‚îÄ‚îÄ booking_Aizeder_Eco_Container_20251106_143230.png
‚îÇ
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ competitors.json               ‚Üê Configuraci√≥n de propiedades
‚îÇ
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ airbnb_scraper.py
    ‚îú‚îÄ‚îÄ booking_scraper.py
    ‚îú‚îÄ‚îÄ data_manager.py                ‚Üê Gestiona CSV y logs
    ‚îî‚îÄ‚îÄ visualizer.py
```

---

## üîÑ Ciclo de Vida de los Datos

### Datos en `price_history.csv`

**Permanentes y acumulativos:**

```
Scraping 1 (Nov 6) ‚Üí 20 registros ‚Üí CSV con 20 filas
Scraping 2 (Nov 8) ‚Üí 15 registros ‚Üí CSV con 35 filas  ‚Üê Se agregan
Scraping 3 (Nov 10) ‚Üí 18 registros ‚Üí CSV con 53 filas ‚Üê Se agregan
```

**Nunca se sobrescriben, siempre se agregan.**

### Archivos Debug

**Temporales y opcionales:**

```
Scraping 1 ‚Üí debug_A.html (se guarda)
Scraping 2 ‚Üí debug_B.html (se guarda, diferente nombre)
Scraping 3 ‚Üí debug_C.html (se guarda, diferente nombre)

Puedes borrar todos los archivos debug sin afectar los datos.
```

---

## üéõÔ∏è Control de Archivos Debug desde la Interfaz

### Estado Actual (Desactivado)

En `app.py`:
```python
airbnb_results = airbnb.scrape_date_range(
    ...,
    debug_first=False  # ‚Üê No genera archivos debug
)

booking_results = booking.scrape_date_range(
    ...,
    debug_first=False  # ‚Üê No genera archivos debug
)
```

### Si Quieres Activar Debug

**Opci√≥n 1: Cambiar en app.py (permanente)**
```python
debug_first=True  # Guarda HTML/PNG del primer d√≠a scrapeado
```

**Opci√≥n 2: Agregar toggle en interfaz (futuro)**
```python
# En render_scraping_interface():
enable_debug = st.checkbox("üêõ Guardar archivos debug", value=False)

# Luego pasar:
debug_first=enable_debug
```

---

## üßπ Gesti√≥n de Archivos Debug

### Borrar Archivos Antiguos

**Manualmente:**
```bash
cd /workspaces/price-monitor/debug
rm *.html *.png
```

**Script autom√°tico** (futuro):
```python
# Borrar archivos debug > 7 d√≠as
import os
from datetime import datetime, timedelta

debug_dir = 'debug'
cutoff = datetime.now() - timedelta(days=7)

for file in os.listdir(debug_dir):
    filepath = os.path.join(debug_dir, file)
    file_time = datetime.fromtimestamp(os.path.getmtime(filepath))
    if file_time < cutoff:
        os.remove(filepath)
        print(f"Eliminado: {file}")
```

---

## üìä Comparaci√≥n: CSV vs Debug

| Caracter√≠stica | price_history.csv | Archivos Debug |
|----------------|-------------------|----------------|
| **Prop√≥sito** | Base de datos principal | Troubleshooting |
| **Contenido** | Precios extra√≠dos | HTML/PNG capturados |
| **Generaci√≥n** | Siempre | Solo cuando `debug=True` o error |
| **Acumulaci√≥n** | Se agregan filas | Archivos independientes |
| **Necesario** | ‚úÖ S√≠ | ‚ùå No |
| **Usado por app** | ‚úÖ S√≠ (visualizaciones) | ‚ùå No |
| **Tama√±o** | Peque√±o (CSV) | Grande (HTML/PNG) |
| **Backup** | Recomendado | Opcional |

---

## üéØ Flujo Detallado Paso a Paso

### Ejemplo Real: Scrapear "Aizeder Eco Container"

**Paso 1: Usuario configura**
```
Propiedad: Aizeder Eco Container
Fechas: 6/11 - 13/11 (7 d√≠as)
Noches: 2
Hu√©spedes: 2
Plataformas: Airbnb + Booking
```

**Paso 2: App verifica anti-duplicado**
```python
is_recent = dm.is_recent_same_run(...)  # ¬øYa se scrape√≥ en 48h?
if is_recent and not force_run:
    return  # Bloqueado
```

**Paso 3: Scrapear Airbnb (7 d√≠as)**
```
Para cada d√≠a (6/11, 7/11, 8/11, ..., 12/11):
  1. Construir URL con fechas
  2. Abrir navegador Playwright
  3. Navegar a Airbnb
  4. Esperar carga
  5. Buscar precio en selectores CSS
  6. Extraer precio (ej: $150)
  7. Cerrar navegador
  8. Agregar resultado a lista:
     {platform: 'Airbnb', checkin: '2025-11-06', price_usd: 150, ...}
  
  (Si debug=True Y es el primer d√≠a):
     ‚Üí Guardar airbnb_Aizeder_Eco_Container_20251106_143052.html
     ‚Üí Guardar airbnb_Aizeder_Eco_Container_20251106_143052.png
```

**Paso 4: Scrapear Booking (7 d√≠as)**
```
(Mismo proceso para Booking)
Resultado: 7 registros m√°s
```

**Paso 5: Guardar en CSV**
```python
dm.save_results(results, property_name='Aizeder Eco Container')

# Se agregan 14 filas a price_history.csv (7 Airbnb + 7 Booking)
```

**Paso 6: Registrar ejecuci√≥n**
```python
dm.log_scrape_run(...)  # Para anti-duplicado 48h
```

**Resultado final:**
```
‚úÖ data/price_history.csv ‚Üí +14 filas nuevas
‚úÖ data/scrape_runs.json ‚Üí +1 registro de ejecuci√≥n
‚ùì debug/ ‚Üí 0-2 archivos (solo si debug=True o error)
```

---

## üí° Mejores Pr√°cticas

### ‚úÖ Hacer

1. **Mantener `price_history.csv` siempre**
   - Es tu base de datos principal
   - Hacer backups peri√≥dicos

2. **Borrar archivos debug antiguos**
   - Ocupan espacio innecesariamente
   - No afectan funcionalidad

3. **Activar debug solo cuando hay problemas**
   - √ötil para debugging
   - No necesario en producci√≥n

4. **Verificar el CSV despu√©s de scrapear**
   - Ver que se agregaron las filas correctas
   - Detectar errores temprano

### ‚ùå Evitar

1. **No borrar `price_history.csv`**
   - Perder√≠as todos los datos hist√≥ricos
   - Hacer backup antes

2. **No depender de archivos debug**
   - No son parte del flujo normal
   - Pueden no existir

3. **No asumir que debug ‚Üí datos**
   - Los datos vienen del scraping en vivo
   - Debug es solo copia de respaldo

---

## üîß Configuraci√≥n de Debug (Avanzado)

### Cambiar Directorio de Debug

En `airbnb_scraper.py` y `booking_scraper.py`:
```python
class AirbnbScraper:
    def __init__(self):
        self.debug_dir = 'debug'  # ‚Üê Cambiar aqu√≠
```

### Organizar por Fechas

```python
# Crear subcarpetas por mes
import os
from datetime import datetime

month_dir = datetime.now().strftime("%Y_%m")
self.debug_dir = os.path.join('debug', month_dir)
os.makedirs(self.debug_dir, exist_ok=True)

# Resultado:
# debug/
#   2025_11/
#     airbnb_...
#   2025_12/
#     airbnb_...
```

---

## ‚úÖ Resumen Final

| Pregunta | Respuesta |
|----------|-----------|
| ¬øLos datos vienen de HTML debug? | ‚ùå NO. Se extraen en tiempo real |
| ¬øSe reemplazan archivos debug? | ‚ùå NO. Ahora tienen nombres √∫nicos |
| ¬øNecesito archivos debug? | ‚ùå NO. Son opcionales |
| ¬øD√≥nde est√° la base de datos? | ‚úÖ `data/price_history.csv` |
| ¬øSe pierden datos al borrar debug? | ‚ùå NO. CSV est√° intacto |
| ¬øLos archivos debug se pisan? | ‚ùå NO. Timestamp √∫nico |

---

**Fecha:** 6 de noviembre de 2025  
**Versi√≥n:** 2.1  
**Sistema:** Price Monitor
