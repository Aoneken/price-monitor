# ğŸ”’ Sistema Anti-Duplicado de Scraping (48 horas)

## ğŸ“‹ DescripciÃ³n General

Se implementÃ³ un sistema de control que **previene la ejecuciÃ³n de scrapings duplicados** dentro de una ventana de **48 horas**. El sistema compara la configuraciÃ³n completa de cada ejecuciÃ³n y bloquea automÃ¡ticamente intentos repetidos con los mismos parÃ¡metros.

---

## âœ¨ CaracterÃ­sticas

### 1. **DetecciÃ³n Inteligente**
El sistema compara **todos** los parÃ¡metros de configuraciÃ³n:
- âœ… Nombre de la propiedad
- âœ… Fecha de inicio (check-in)
- âœ… Fecha de fin (check-out)
- âœ… NÃºmero de noches
- âœ… NÃºmero de huÃ©spedes
- âœ… Plataformas seleccionadas (Airbnb, Booking)

### 2. **Ventana de 48 Horas**
- Solo se previenen duplicados en las **Ãºltimas 48 horas**
- DespuÃ©s de 48 horas, la misma configuraciÃ³n puede ejecutarse nuevamente
- El tiempo se calcula desde el timestamp de la ejecuciÃ³n anterior

### 3. **OpciÃ³n de Forzar EjecuciÃ³n**
- Checkbox **"ğŸ”„ Forzar ejecuciÃ³n"** en la interfaz
- Permite anular el control anti-duplicado cuando sea necesario
- Ãštil para debugging o cuando se necesita refrescar datos urgentemente

---

## ğŸ—ï¸ ImplementaciÃ³n TÃ©cnica

### Archivos Modificados

#### 1. `src/data_manager.py`
Nuevos mÃ©todos aÃ±adidos a la clase `DataManager`:

```python
def log_scrape_run(self, property_name, start_date, end_date, nights, guests, platforms):
    """Registra una ejecuciÃ³n de scraping exitosa"""
    # Guarda la configuraciÃ³n y timestamp en data/scrape_runs.json

def is_recent_same_run(self, property_name, start_date, end_date, nights, guests, platforms, window_hours=48):
    """Verifica si ya se ejecutÃ³ la misma configuraciÃ³n en las Ãºltimas window_hours horas"""
    # Retorna True si encuentra una ejecuciÃ³n idÃ©ntica dentro de la ventana de tiempo
```

**Archivo de persistencia:** `data/scrape_runs.json`

#### 2. `app.py`
Modificaciones en las funciones:

**`run_scraping()`**
- Nuevo parÃ¡metro: `force_run=False`
- Chequeo anti-duplicado antes de iniciar scraping
- Muestra warning detallado si se detecta duplicado
- Registra ejecuciÃ³n exitosa despuÃ©s de guardar resultados

**`render_scraping_interface()`**
- Nuevo checkbox: "ğŸ”„ Forzar ejecuciÃ³n"
- Pasa el parÃ¡metro `force_run` a la funciÃ³n de scraping

---

## ğŸ“Š Formato del Log

El archivo `data/scrape_runs.json` almacena cada ejecuciÃ³n:

```json
[
  {
    "property_name": "Aizeder Eco Container House",
    "start_date": "2025-11-06",
    "end_date": "2025-11-13",
    "nights": 2,
    "guests": 2,
    "platforms": ["airbnb", "booking"],
    "ts": "2025-11-06T16:23:51"
  }
]
```

---

## ğŸ”„ Flujo de Funcionamiento

### Escenario 1: Primera EjecuciÃ³n
```
Usuario configura scraping â†’ No hay ejecuciÃ³n previa â†’ âœ… Scraping procede â†’ Se registra en log
```

### Escenario 2: EjecuciÃ³n Duplicada (< 48h)
```
Usuario configura scraping â†’ Se detecta ejecuciÃ³n idÃ©ntica < 48h â†’ âš ï¸ Warning mostrado â†’ Scraping bloqueado
```

### Escenario 3: Forzar EjecuciÃ³n
```
Usuario marca "Forzar ejecuciÃ³n" â†’ Control anti-duplicado desactivado â†’ âœ… Scraping procede â†’ Se registra en log
```

### Escenario 4: DespuÃ©s de 48 Horas
```
Usuario configura scraping â†’ EjecuciÃ³n anterior > 48h â†’ âœ… Scraping procede â†’ Se registra en log
```

---

## ğŸ§ª Testing

Se incluye el script `test_anti_duplicate.py` que verifica:

âœ… Test 1: No detecta duplicado cuando no hay ejecuciones previas  
âœ… Test 2: Registra correctamente una nueva ejecuciÃ³n  
âœ… Test 3: Detecta duplicado con configuraciÃ³n idÃ©ntica  
âœ… Test 4: No detecta duplicado con noches diferentes  
âœ… Test 5: No detecta duplicado con plataformas diferentes  
âœ… Test 6: No detecta duplicado con propiedad diferente  

**Ejecutar tests:**
```bash
python test_anti_duplicate.py
```

---

## ğŸ“ Mensaje de Warning

Cuando se detecta un duplicado, el usuario ve:

```
âš ï¸ EjecuciÃ³n Duplicada Detectada

Ya existe un scraping con esta configuraciÃ³n para 'Aizeder Eco Container House' 
realizado en las Ãºltimas 48 horas.

- Propiedad: Aizeder Eco Container House
- Fechas: 06/11/2025 - 13/11/2025
- Noches: 2
- HuÃ©spedes: 2
- Plataformas: airbnb, booking

Para ejecutarlo de todas formas, marca la opciÃ³n "Forzar ejecuciÃ³n" y vuelve a intentar.
```

---

## ğŸ’¡ Ventajas

1. **Ahorro de recursos**: Evita scrapings innecesarios
2. **ProtecciÃ³n anti-ban**: Reduce requests repetidos a las plataformas
3. **Control de costos**: Minimiza uso de recursos computacionales
4. **Flexibilidad**: OpciÃ³n de override cuando sea necesario
5. **Trazabilidad**: Log completo de todas las ejecuciones

---

## ğŸ”§ ConfiguraciÃ³n

### Cambiar la ventana de tiempo

Por defecto es **48 horas**, pero se puede ajustar modificando el parÃ¡metro en `app.py`:

```python
is_recent = data_manager.is_recent_same_run(
    # ... otros parÃ¡metros ...
    window_hours=48  # â† Cambiar aquÃ­ (ej: 24, 72, etc.)
)
```

### Desactivar completamente

Para desactivar el control (no recomendado):

1. Comentar el bloque de chequeo en `run_scraping()`
2. O siempre marcar "Forzar ejecuciÃ³n"

---

## ğŸ“… Fecha de ImplementaciÃ³n

**6 de noviembre de 2025**

---

## âœ… Estado

**âœ“ Implementado y probado**  
**âœ“ Tests pasando correctamente**  
**âœ“ Integrado en UI de Streamlit**
