# üìä Price Monitor V3

> **‚ö†Ô∏è IMPORTANTE**: Este proyecto est√° en la rama `v3` con implementaci√≥n completa del SDK V3.  
> Para documentaci√≥n completa, ver **[README_V3.md](README_V3.md)**

## üöÄ Inicio R√°pido

```bash
# Instalar dependencias
pip install -r requirements.txt
playwright install chromium

# Iniciar aplicaci√≥n
streamlit run app.py

# Ejecutar scraping autom√°tico
python scheduler_v3.py --help
```

---

## ‚ú® Novedades V3

### SDK Completo
- ‚úÖ **Parsers modulares** por plataforma (Airbnb, Booking, Expedia)
- ‚úÖ **Robots con Playwright** y configuraci√≥n stealth
- ‚úÖ **Normalizers** para datos multi-divisa y validaci√≥n
- ‚úÖ **Orchestrator** para coordinaci√≥n multi-plataforma
- ‚úÖ **Quality scoring** (0-1) por confiabilidad de fuente

### Aplicaci√≥n Web
- ‚úÖ **Scraping V3**: UI para scraping manual con configuraci√≥n flexible
- ‚úÖ **Monitoreo V3**: Dashboard con m√©tricas en tiempo real
- ‚úÖ **Sistema de cach√©**: Evita re-scraping innecesario (24h default)
- ‚úÖ **Logging completo**: logs/scheduler_v3.log

### Automatizaci√≥n
- ‚úÖ **Scheduler CLI**: Ejecuci√≥n batch desde terminal
- ‚úÖ **Integraci√≥n con BD**: Mapeo autom√°tico a schema legacy
- ‚úÖ **Filtrado por plataforma**: Scraping selectivo
- ‚úÖ **Tests unitarios**: 26 tests, 100% passing

---

## üìÅ Documentaci√≥n

### Para Usuarios
- **[README_V3.md](README_V3.md)**: Gu√≠a completa de uso
- **[SDK_V3_README.md](SDK_V3_README.md)**: Documentaci√≥n del SDK

### Para Desarrolladores
- **[IMPLEMENTACION_SDK_V3_COMPLETA.md](IMPLEMENTACION_SDK_V3_COMPLETA.md)**: Resumen t√©cnico
- **docs_v3/metodologias/**: Metodolog√≠as por plataforma
- **tests_v3/**: Suite de tests unitarios

---

## üéØ Estado del Proyecto

**Versi√≥n**: 3.0.0  
**Branch**: v3  
**Status**: ‚úÖ **Producci√≥n Ready**

### Completado
- [x] SDK V3 con parsers, robots, normalizers
- [x] Integraci√≥n completa con base de datos
- [x] UI Streamlit funcional (Scraping + Monitoreo)
- [x] Scheduler CLI con logging
- [x] Sistema de cach√© inteligente
- [x] Tests unitarios (26 tests, 100% passing)

### En Progreso
- [ ] Tests de integraci√≥n con fixtures HTML
- [ ] Validaci√≥n con URLs reales de producci√≥n

### Roadmap
- [ ] Scraping concurrente (asyncio)
- [ ] Alertas de cambios de precio
- [ ] API REST
- [ ] Soporte para m√°s plataformas

---

## üèóÔ∏è Arquitectura V3

```
src/
‚îú‚îÄ‚îÄ parsers/          # Extracci√≥n de datos HTML
‚îú‚îÄ‚îÄ robots/           # Navegaci√≥n Playwright
‚îú‚îÄ‚îÄ normalizers/      # Normalizaci√≥n y validaci√≥n
‚îú‚îÄ‚îÄ persistence/      # Integraci√≥n con BD
‚îî‚îÄ‚îÄ orchestrator_v3   # Coordinador multi-plataforma
```

**Flujo de Datos**:
```
URL + Fechas ‚Üí Robot (Playwright) ‚Üí HTML ‚Üí Parser ‚Üí Normalizer ‚Üí Quote ‚Üí BD
```

---

## üìä Caracter√≠sticas Principales (V3)

### ü§ñ Scraping Inteligente
- **3 plataformas**: Airbnb, Booking, Expedia
- **Playwright**: Navegaci√≥n robusta y stealth
- **Quality scoring**: Confiabilidad 0-1 por fuente
- **Manejo de errores**: C√≥digos espec√≠ficos por plataforma

### üìà Monitoreo en Tiempo Real
- **M√©tricas generales**: Total precios, actividad 24h, cobertura
- **Distribuci√≥n**: URLs con datos por plataforma
- **Actividad reciente**: 50 √∫ltimos scrapeos con estado
- **Tendencias**: Gr√°ficos hist√≥ricos 30 d√≠as

### üóÑÔ∏è Base de Datos
- **SQLite** optimizado con √≠ndices
- **Cach√© inteligente**: Configurable (default 24h)
- **Hist√≥rico completo**: Precios por noche
- **Tracking de errores**: Para diagn√≥stico

---

## üöÄ Uso R√°pido

### Interfaz Web
```bash
streamlit run app.py
```
Ir a:
- **"Scraping V3"**: Ejecutar scraping manual
- **"Monitoreo V3"**: Ver m√©tricas y tendencias

### CLI (Automatizaci√≥n)
```bash
# Scrapear todas las URLs
python scheduler_v3.py

# Solo una plataforma
python scheduler_v3.py --platform Airbnb

# Configuraci√≥n personalizada
python scheduler_v3.py --days-ahead 60 --nights 3 --cache-hours 48
```

### Tests
```bash
# Tests unitarios
pytest tests_v3/ -v

# Demo SDK (sin navegaci√≥n)
python demo_v3.py

# Test r√°pido (1 URL real)
python test_scheduler_quick.py
```

---

## üì¶ Estructura del Proyecto

```
price-monitor/
‚îú‚îÄ‚îÄ src/                    # SDK V3
‚îÇ   ‚îú‚îÄ‚îÄ parsers/           # Airbnb, Booking, Expedia
‚îÇ   ‚îú‚îÄ‚îÄ robots/            # Navegaci√≥n Playwright
‚îÇ   ‚îú‚îÄ‚îÄ normalizers/       # Normalizaci√≥n de datos
‚îÇ   ‚îú‚îÄ‚îÄ persistence/       # Integraci√≥n BD
‚îÇ   ‚îî‚îÄ‚îÄ orchestrator_v3.py
‚îú‚îÄ‚îÄ pages/                  # UI Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ 6_Scraping_V3.py
‚îÇ   ‚îî‚îÄ‚îÄ 7_Monitoreo_V3.py
‚îú‚îÄ‚îÄ tests_v3/              # Tests unitarios
‚îú‚îÄ‚îÄ database/              # SQLite DB
‚îú‚îÄ‚îÄ docs_v3/               # Documentaci√≥n
‚îú‚îÄ‚îÄ logs/                  # Logs de ejecuci√≥n
‚îú‚îÄ‚îÄ scheduler_v3.py        # CLI scheduler
‚îú‚îÄ‚îÄ demo_v3.py            # Demo del SDK
‚îî‚îÄ‚îÄ app.py                # App principal
```

---

## üîß Tecnolog√≠as

- **Python 3.12+**
- **Streamlit 1.29**: Interfaz web
- **Playwright 1.48**: Scraping con navegador
- **SQLite**: Base de datos
- **Pandas**: An√°lisis de datos
- **Pytest**: Testing

---

## üìÑ Licencia

MIT License

---

## üìû M√°s Informaci√≥n

Ver **[README_V3.md](README_V3.md)** para documentaci√≥n completa.

---

**Autor**: Aoneken  
**√öltima actualizaci√≥n**: 2025-01-08  
**Branch**: v3  
**Commits**: Ver `git log --oneline`

---

## Legacy (V1/V2)

El c√≥digo de versiones anteriores se encuentra en `legacy/` para referencia hist√≥rica.

Estado V3 (rama `v3`): Skeleton m√≠nimo activado.

- N√∫cleo conservado: Solo la tabla `Establecimientos` (schema m√≠nimo en `database/schema.sql`).
- Documentaci√≥n constitucional: ver `docs_v3/` (arquitectura, dominio, contratos y migraci√≥n).
- C√≥digo V1/V2 reubicado en `legacy/` para referencia hist√≥rica y comparativa.
- A partir de aqu√≠, se reconstruir√° la app conforme a los contratos definidos en V3.

Documentaci√≥n V3 (√≠ndice):
- `docs_v3/VISION_NEGOCIO_V3.md`
- `docs_v3/FASE_0_CONSTITUCION_Y_MIGRACION.md`
- `docs_v3/FASE_1_DATOS_Y_DOMINIO.md`
- `docs_v3/FASE_2_INGESTA_Y_SCRAPING.md`
- `docs_v3/FASE_3_PERSISTENCIA_Y_NORMALIZACION.md`
- `docs_v3/FASE_4_OBSERVABILIDAD_Y_TESTING.md`
- `docs_v3/FASE_5_UI_Y_API.md`
- `docs_v3/FASE_6_SEGURIDAD_Y_OPERACION.md`

---

**Sistema de Inteligencia de Precios para Plataformas de Alojamiento**

Price Monitor es una aplicaci√≥n web interna que permite gestionar un portafolio de establecimientos, automatizar el scraping de precios en plataformas como Booking y Airbnb, y visualizar insights de pricing y ocupaci√≥n.

---

## üéØ Caracter√≠sticas Principales (Legacy)

- **üè† Gesti√≥n de Establecimientos**: CRUD completo para administrar propiedades y URLs de monitoreo
- **ü§ñ Scraping Automatizado**: Extracci√≥n inteligente de precios con l√≥gica 3‚Üí2‚Üí1 noches
- **üíæ Base de Datos Hist√≥rica**: SQLite optimizado con √≠ndices y esquema normalizado
- **üìä Dashboard Interactivo**: Visualizaci√≥n de tendencias de precios y ocupaci√≥n
- **üîí Anti-Detecci√≥n**: Modo stealth con Playwright para evitar bloqueos
- **‚è±Ô∏è L√≥gica de Frescura**: Solo actualiza datos > 48 horas (configurable)

---

## üèóÔ∏è Arquitectura (Legacy)

Nota: La arquitectura detallada a continuaci√≥n corresponde al legado V1/V2. El dise√±o vigente para V3 est√° en `docs_v3/ARQUITECTURA_V3.md`. La implementaci√≥n V3 se ir√° incorporando gradualmente.

### Stack Tecnol√≥gico

- **Frontend**: Streamlit (interfaz web interactiva)
- **Backend**: Python 3.11+
- **Base de Datos**: SQLite con esquema normalizado (3 tablas)
- **Scraping**: Playwright con modo stealth
- **Visualizaci√≥n**: Plotly para gr√°ficos interactivos

### Patrones de Dise√±o

- **Strategy Pattern**: Robots intercambiables por plataforma
- **Factory Pattern**: Creaci√≥n din√°mica de robots
- **Singleton**: Gestor √∫nico de base de datos
- **Repository Pattern**: Abstracci√≥n de acceso a datos

### Estructura del Proyecto (Legado en `legacy/`)

```
price-monitor/
‚îú‚îÄ‚îÄ legacy/                         # C√≥digo V1/V2 preservado
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ scrapers/
‚îÇ   ‚îú‚îÄ‚îÄ pages/
‚îÇ   ‚îú‚îÄ‚îÄ ui/
‚îÇ   ‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ tests_root/
‚îú‚îÄ‚îÄ docs_v3/                        # Constituci√≥n y gu√≠as V3
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ settings.py                 # Configuraci√≥n centralizada
‚îî‚îÄ‚îÄ database/
  ‚îú‚îÄ‚îÄ schema.sql                  # (V3) Solo Establecimientos
  ‚îî‚îÄ‚îÄ db_manager.py               # (V3) CRUD m√≠nimo
```

---

## üöÄ Instalaci√≥n

### Requisitos Previos

- Python 3.11 o superior
- pip (gestor de paquetes de Python)

### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/tu-usuario/price-monitor.git
cd price-monitor
```

### Paso 2: Crear Entorno Virtual

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### Paso 3: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 4: Instalar Playwright

```bash
playwright install chromium
```

### Paso 5: Configurar Variables de Entorno

```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

### Paso 6: Inicializar Base de Datos

La base de datos se inicializa autom√°ticamente al primer uso.

---

## üíª Uso

### Iniciar la Aplicaci√≥n

```bash
streamlit run app.py
```

La aplicaci√≥n se abrir√° en `http://localhost:8501`

### Flujo de Trabajo

1. **Establecimientos** (Pesta√±a 1)
   - Crear un establecimiento
   - Agregar URLs de Booking/Airbnb
   - Activar/desactivar monitoreo

2. **Scraping** (Pesta√±a 2)
   - Seleccionar establecimiento
   - Definir rango de fechas
   - Iniciar scraping y ver progreso

3. **Base de Datos** (Pesta√±a 3)
   - Explorar datos con filtros
   - Exportar a CSV

4. **Dashboard** (Pesta√±a 4)
   - Visualizar gr√°ficos de tendencias
   - Comparar plataformas
   - Analizar KPIs

---

## ‚öôÔ∏è Configuraci√≥n

### Archivo `.env`

```env
# Base de Datos
DATABASE_PATH=./database/price_monitor.db

# Scraping
SCRAPER_MIN_DELAY=3
SCRAPER_MAX_DELAY=8
SCRAPER_MAX_RETRIES=3
SCRAPER_HEADLESS=True

# Frescura de Datos
DATA_FRESHNESS_HOURS=48
```

### Selectores CSS

Los selectores se configuran en `scrapers/config/selectors.json`. Esto permite actualizar selectores sin tocar el c√≥digo.

Ejemplo:
```json
{
  "Booking": {
    "precio": [
      "[data-testid='price-label']",
      ".priceDisplay"
    ],
    "no_disponible": [
      "[data-testid='calendar-unavailable']"
    ]
  }
}
```

---

## ü§ñ Agregar Nuevas Plataformas

### 1. Crear el Robot

```python
# scrapers/robots/vrbo_robot.py
from scrapers.base_robot import BaseRobot

class VrboRobot(BaseRobot):
    def __init__(self):
        super().__init__('Vrbo')
        self._cargar_selectores()
    
    def buscar(self, browser, url_base, fecha_checkin):
        # Implementar l√≥gica de scraping
        pass
    
    def construir_url(self, url_base, fecha_checkin, noches):
        return URLBuilder.vrbo_url(url_base, fecha_checkin, noches)
```

### 2. Registrar en el Factory

```python
# scrapers/robot_factory.py
from scrapers.robots.vrbo_robot import VrboRobot

class RobotFactory:
    _robots = {
        'Booking': BookingRobot,
        'Airbnb': AirbnbRobot,
        'Vrbo': VrboRobot,  # Agregar aqu√≠
    }
```

### 3. Agregar Selectores

```json
// scrapers/config/selectors.json
{
  "Vrbo": {
    "precio": ["[data-testid='price']"],
    "no_disponible": ["text=/not available/i"]
  }
}
```

### 4. Actualizar Constraint de BD

```sql
-- database/schema.sql
CHECK(plataforma IN ('Booking', 'Airbnb', 'Vrbo'))
```

---

## üß™ Testing

```bash
# Ejecutar tests
python -m pytest tests/

# Con cobertura
python -m pytest tests/ --cov=scrapers --cov=database
```

---

## üìä Base de Datos

### Esquema

```
Establecimientos (id_establecimiento, nombre_personalizado, fecha_creacion)
    ‚Üì
Plataformas_URL (id_plataforma_url, id_establecimiento, plataforma, url, esta_activa)
    ‚Üì
Precios (id_plataforma_url, fecha_noche, precio_base, esta_ocupado, fecha_scrape, ...)
```

### L√≥gica de Negocio

- **UPSERT**: Inserta o actualiza precios seg√∫n clave primaria compuesta (URL + Fecha)
- **L√≥gica 48h**: Solo actualiza datos con > 48 horas de antig√ºedad
- **L√≥gica 3‚Üí2‚Üí1**: Busca disponibilidad para 3, 2 y 1 noche(s) en ese orden
- **Ocupaci√≥n**: Si precio = 0, se asume `esta_ocupado = TRUE`

---

## üîê Seguridad y Buenas Pr√°cticas

### Anti-Detecci√≥n

- User-Agent rotation
- Headless mode configurable
- Random delays entre peticiones (3-8s)
- Exponential backoff en reintentos
- Stealth mode con Playwright

### Rate Limiting

```python
# Configurado en .env
SCRAPER_MIN_DELAY=3
SCRAPER_MAX_DELAY=8
```

### Limitaciones

- **SQLite**: M√°ximo 5 usuarios simult√°neos (para m√°s, migrar a PostgreSQL)
- **Bloqueos**: Los sitios pueden detectar scraping intensivo
- **Selectores**: Pueden cambiar sin aviso (mantenimiento peri√≥dico necesario)

---

## üêõ Troubleshooting

### Error: "Playwright not installed"

```bash
playwright install chromium
```

### Error: "Database is locked"

SQLite no soporta m√∫ltiples escrituras simult√°neas. Espera a que termine la operaci√≥n actual.

### Error: "CAPTCHA detected"

- Reduce la frecuencia de scraping (aumenta delays)
- Usa `SCRAPER_HEADLESS=False` para debugging
- Verifica que stealth mode est√© activo

### Selectores no funcionan

1. Abre `scrapers/config/selectors.json`
2. Actualiza selectores inspeccionando la p√°gina web
3. Agrega selectores alternativos para redundancia

---

## üó∫Ô∏è Roadmap

### Versi√≥n 1.0 (MVP) ‚úÖ
- [x] CRUD de establecimientos
- [x] Scraping de Booking y Airbnb
- [x] Dashboard b√°sico
- [x] L√≥gica de 48h y 3‚Üí2‚Üí1

### Versi√≥n 1.1 (En desarrollo)
- [ ] Soporte para Vrbo
- [ ] Tests automatizados
- [ ] Logging avanzado
- [ ] Notificaciones por email

### Versi√≥n 2.0 (Futuro)
- [ ] M√≥dulo de an√°lisis competitivo
- [ ] Recomendaciones de pricing con IA
- [ ] Integraci√≥n con PMS
- [ ] API REST

---

## üë• Contribuciones

Las contribuciones son bienvenidas. Por favor:

1. Fork el repositorio
2. Crea una rama para tu feature (`git checkout -b feature/NuevaPlataforma`)
3. Commit tus cambios (`git commit -m 'Add Vrbo support'`)
4. Push a la rama (`git push origin feature/NuevaPlataforma`)
5. Abre un Pull Request

---

## üìÑ Licencia

Este proyecto es de uso interno. Todos los derechos reservados.

---

## üìû Contacto

Para preguntas o soporte, contacta al equipo de desarrollo.

---

## üôè Agradecimientos

- **Streamlit**: Framework de UI
- **Playwright**: Herramienta de scraping
- **Plotly**: Visualizaciones interactivas

---

**Nota**: Este software es para uso educativo e interno. El scraping puede violar los t√©rminos de servicio de las plataformas. √ösalo bajo tu propia responsabilidad y respetando las pol√≠ticas de robots.txt.
